# This file is automatically generated by pyo3_stub_gen
# ruff: noqa: E501, F401

import builtins
import typing
from enum import Enum


class DataType(Enum):
    Float = 0
    Half = 1
    Int8 = 2
    Int32 = 3
    UINT8 = 5
    FP8 = 6
    BF16 = 7
    INT64 = 8
    INT4 = 9
    FP4 = 10
    E8M0 = 11


class AsyncInferenceClient:
    def __new__(cls, socket_path: builtins.str) -> AsyncInferenceClient: ...

    async def infer(self, inputs: dict) -> builtins.dict[builtins.str, Tensor]:
        r"""
        异步推理调用
        """

    async def test_connection(self) -> builtins.bool:
        r"""
        测试连接
        """


class InferenceClient:
    def __new__(cls, socket_path: builtins.str) -> InferenceClient: ...

    def infer(self, inputs: dict) -> builtins.dict[builtins.str, Tensor]: ...

    def test_connection(self) -> builtins.bool: ...


class TRTInferenceServer:
    def new(self) -> TRTInferenceServer: ...

    def start_tensorrt_server(self, engine_path: builtins.str, max_batch_size: builtins.int, socket_path: builtins.str,
                              batch_timeout_ms: builtins.int) -> None:
        r"""
        启动TensorRT推理服务器
        """

    def stop_server(self) -> None:
        r"""
        停止服务器
        """

    def is_running(self) -> builtins.bool:
        r"""
        检查服务器是否在运行
        """


class Tensor:
    def __new__(cls, data: typing.Sequence[builtins.int], shape: typing.Sequence[builtins.int],
                dtype: DataType) -> Tensor: ...

    def get_bytes(self) -> builtins.bytes: ...

    def get_shape(self) -> builtins.list[builtins.int]: ...

    def get_dtype(self) -> DataType: ...
